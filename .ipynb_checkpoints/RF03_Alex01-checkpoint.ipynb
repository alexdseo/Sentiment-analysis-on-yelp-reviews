{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nchar</th>\n",
       "      <th>nword</th>\n",
       "      <th>gem</th>\n",
       "      <th>incredible</th>\n",
       "      <th>die</th>\n",
       "      <th>knowledgeable</th>\n",
       "      <th>highly</th>\n",
       "      <th>amazing</th>\n",
       "      <th>favorites</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>...</th>\n",
       "      <th>disappointing</th>\n",
       "      <th>manager</th>\n",
       "      <th>dirty</th>\n",
       "      <th>mediocre</th>\n",
       "      <th>poor</th>\n",
       "      <th>terrible</th>\n",
       "      <th>awful</th>\n",
       "      <th>rude</th>\n",
       "      <th>horrible</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "      <td>34217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>599.985124</td>\n",
       "      <td>110.078587</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>0.099161</td>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.041295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019026</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.015694</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>0.011427</td>\n",
       "      <td>0.016278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>534.629585</td>\n",
       "      <td>98.524370</td>\n",
       "      <td>0.160764</td>\n",
       "      <td>0.121585</td>\n",
       "      <td>0.314872</td>\n",
       "      <td>0.108689</td>\n",
       "      <td>0.164996</td>\n",
       "      <td>0.338586</td>\n",
       "      <td>0.125468</td>\n",
       "      <td>0.221628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145324</td>\n",
       "      <td>0.227349</td>\n",
       "      <td>0.128395</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.146851</td>\n",
       "      <td>0.147050</td>\n",
       "      <td>0.108793</td>\n",
       "      <td>0.163463</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>0.135900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>439.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>778.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>969.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              nchar         nword           gem    incredible           die  \\\n",
       "count  34217.000000  34217.000000  34217.000000  34217.000000  34217.000000   \n",
       "mean     599.985124    110.078587      0.022737      0.013444      0.079025   \n",
       "std      534.629585     98.524370      0.160764      0.121585      0.314872   \n",
       "min       46.000000     10.000000      0.000000      0.000000      0.000000   \n",
       "25%      244.000000     44.000000      0.000000      0.000000      0.000000   \n",
       "50%      439.000000     81.000000      0.000000      0.000000      0.000000   \n",
       "75%      778.000000    143.000000      0.000000      0.000000      0.000000   \n",
       "max     5000.000000    969.000000      5.000000      2.000000      6.000000   \n",
       "\n",
       "       knowledgeable        highly       amazing     favorites     wonderful  \\\n",
       "count   34217.000000  34217.000000  34217.000000  34217.000000  34217.000000   \n",
       "mean        0.011836      0.026215      0.099161      0.014671      0.041295   \n",
       "std         0.108689      0.164996      0.338586      0.125468      0.221628   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max         2.000000      3.000000      4.000000      2.000000      4.000000   \n",
       "\n",
       "           ...       disappointing       manager         dirty      mediocre  \\\n",
       "count      ...        34217.000000  34217.000000  34217.000000  34217.000000   \n",
       "mean       ...            0.019026      0.029839      0.012012      0.015694   \n",
       "std        ...            0.145324      0.227349      0.128395      0.131378   \n",
       "min        ...            0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...            0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...            0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...            0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...            3.000000      6.000000      3.000000      3.000000   \n",
       "\n",
       "               poor      terrible         awful          rude      horrible  \\\n",
       "count  34217.000000  34217.000000  34217.000000  34217.000000  34217.000000   \n",
       "mean       0.018821      0.018821      0.010843      0.018529      0.011427   \n",
       "std        0.146851      0.147050      0.108793      0.163463      0.115003   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        4.000000      4.000000      3.000000      8.000000      3.000000   \n",
       "\n",
       "              worst  \n",
       "count  34217.000000  \n",
       "mean       0.016278  \n",
       "std        0.135900  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        3.000000  \n",
       "\n",
       "[8 rows x 502 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_Madison.csv\")\n",
    "#train = train[:20]\n",
    "test = pd.read_csv(\"test_Madison.csv\")\n",
    "#names = train[\"name\"]\n",
    "train_star = train[\"star\"]\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "train_name = train['name']\n",
    "test_name = test['name']\n",
    "train_city = train['city']\n",
    "test_city = test['city']\n",
    "train_post = train['postal_code']\n",
    "test_post = test['postal_code']\n",
    "train_text = train['text']\n",
    "test_text = test['text']\n",
    "\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)\n",
    "train.drop('name', axis=1, inplace=True)\n",
    "test.drop('name', axis=1, inplace=True)\n",
    "train.drop('city', axis=1, inplace=True)\n",
    "test.drop('city', axis=1, inplace=True)\n",
    "train.drop('postal_code', axis=1, inplace=True)\n",
    "test.drop('postal_code', axis=1, inplace=True)\n",
    "train.drop('text', axis=1, inplace=True)\n",
    "test.drop('text', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#train.info(verbose=True)\n",
    "y_train = train_star\n",
    "#train.head(5)\n",
    "test.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest score: 0.3804 (0.0196)\n",
      "\n",
      "MLR score: 0.0000 (0.0000)\n",
      "\n",
      "knn score: 0.9937 (0.0128)\n",
      "\n",
      "SVM score: 0.8445 (0.2552)\n",
      "\n",
      "NB score: 0.4376 (0.0300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "positiveCount = []\n",
    "negativeCount = []\n",
    "positiveOverall = []\n",
    "#ratingArray = []\n",
    "#nwords = []\n",
    "posnshort = []\n",
    "negnlong = []\n",
    "nchars = []\n",
    "negativeplus = []\n",
    "#avgChars = []\n",
    "#posnegratio= []\n",
    "#numReviews = []\n",
    "positiveWords = [\"gem\", \"highly\", \"incredible\", \"amazing\", \"die\", \"favorites\", \"wonderful\", \"perfect\", \"fantastic\", \"notch\",\n",
    "                 \"favorite\", \"awesome\", \"outstanding\", \"yum\", \"delicious\", \"excellent\", \"perfectly\", \"loved\", \"helpful\", \"best\", \n",
    "                 \"savory\", \"cozy\", \"unique\", \"yummy\", \"glad\", \"homemade\", \"best\", \"love\", \"lovely\", \"always\", \"friendly\", \n",
    "                 \"reasonable\", \"beautiful\", \"recommended\", \"fashioned\", \"classic\", \"traditional\", \"great\", \"fresh\", \"definitely\",\n",
    "                 \"healthy\", \"decent\", \"generous\", \"comfortable\", \"rich\", \"recommend\", \"local\", \"authentic\", \"flavorful\",\n",
    "                 \"enjoyed\", \"pleased\", \"flavors\", \"super\", \"happy\", \"absolutely\", \"tasty\", \"enjoy\", \"fun\", \"reasonably\", \"plenty\",\n",
    "                 \"attentive\", \"truly\", \"fancy\", \"wow\", \"must\", \"nicely\", \"every\", \"quick\", \"easily\", \"early\", \"craving\", \"well\"]\n",
    "negativeWords = [\"disappointing\", \"weird\", \"issue\", \"none\", \"last\", \"problem\", \"dirty\", \"mediocre\", \"ok\", \"poor\", \"terrible\",\n",
    "                 \"awful\", \"rude\", \"horrible\", \"worst\", \"overpriced\", \"needed\", \"barely\", \"sorry\", \"waited\", \"soggy\", \"waiting\",\n",
    "                 \"bland\", \"forgot\", \"hope\",\"unfortunately\", \"sad\", \"away\", \"bad\", \"loud\", \"overly\", \"greasy\", \"frozen\", \"dry\",\n",
    "                 \"empty\", \"never\", \"less\", \"hard\", \"expensive\", \"tiny\", \"however\", \"wrong\", \"longer\", \"nothing\", \"average\", \n",
    "                 \"cold\", \"slow\", \"lack\", \"avoid\", \"forget\", \"left\", \"worst\"]\n",
    "for i in range(0, len(y_train)):\n",
    "    #print(i)\n",
    "    #print(len(names))\n",
    "    posC = 0\n",
    "    negC = 0\n",
    "    for word in positiveWords:\n",
    "        wordCount = train[word][i]\n",
    "        posC+=wordCount\n",
    "    for negWord in negativeWords:\n",
    "        negWordCount = train[negWord][i]\n",
    "        negC+=negWordCount\n",
    "    nword = np.array(train[\"nword\"])[i]\n",
    "    nchar = np.array(train[\"nchar\"])[i]\n",
    "    #avgChars.append(nchar/nword)\n",
    "    #nwords.append(nword)\n",
    "    #positiveCount.append(posC)\n",
    "    #negativeCount.append(negC)\n",
    "    if negC>3:\n",
    "        negativeplus.append(-1)\n",
    "    else:\n",
    "        negativeplus.append(0)\n",
    "    #posnegratio.append((posC)/(negC + 1))\n",
    "    nchars.append((nchar-604.022230)/532.547462)\n",
    "    if nword<110:\n",
    "        posnshort.append(posC * 1.5)\n",
    "        negnlong.append(negC)\n",
    "    else:\n",
    "        posnshort.append(posC)\n",
    "        negnlong.append(negC * 1.5)\n",
    "    if posC>negC:\n",
    "        positiveOverall.append(1)\n",
    "    elif posC<negC:\n",
    "        positiveOverall.append(-1.5)\n",
    "    else:\n",
    "        positiveOverall.append(0)\n",
    "    #ratingArray.append(ratingAverage[names[i]])\n",
    "    #numReviews.append(ratingCount[names[i]])\n",
    "#predictors = np.array([positiveCount, negativeCount, ratingArray])\n",
    "#predictors = np.array([nwords, positiveOverall, ratingArray, positiveCount, negativeCount, posRatio])\n",
    "#posRatio = np.array(posRatio)\n",
    "#print(posRatio)\n",
    "predictors = np.array([positiveOverall, posnshort, negnlong, nchars, negativeplus])\n",
    "predictors = predictors.T\n",
    "\n",
    "x_train = pd.DataFrame(predictors)\n",
    "x_train.columns = ['Overall','PosShort','NegLong','nChars', 'negative+']\n",
    "#x_train.head(5)\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "def rmse_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=96).get_n_splits(train.values)\n",
    "    rmse = np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return (rmse)\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "model_rf = random_forest.fit(x_train, y_train)\n",
    "reg = linear_model.LinearRegression()\n",
    "model_reg = reg.fit(x_train, y_train)\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "model_knn = knn.fit(x_train, y_train)\n",
    "linear_svc = LinearSVC()\n",
    "model_svc = linear_svc.fit(x_train, y_train)\n",
    "gaussian = GaussianNB()\n",
    "model_gau = gaussian.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#score1 = rmse_cv(model_rf)\n",
    "#print(\"RandomForest score: {:.4f} ({:.4f})\\n\".format(score1.mean(), score1.std()))\n",
    "#score2 = rmse_cv(model_reg)\n",
    "#print(\"MLR score: {:.4f} ({:.4f})\\n\".format(score2.mean(), score2.std()))\n",
    "#score3 = rmse_cv(model_knn)\n",
    "#print(\"knn score: {:.4f} ({:.4f})\\n\".format(score3.mean(), score3.std()))\n",
    "#score4 = rmse_cv(model_svc)\n",
    "#print(\"SVM score: {:.4f} ({:.4f})\\n\".format(score4.mean(), score4.std()))\n",
    "#score5 = rmse_cv(model_rf)\n",
    "#print(\"NB score: {:.4f} ({:.4f})\\n\".format(score5.mean(), score5.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.44\n",
      "40.02\n",
      "56.94\n",
      "42.95\n",
      "44.76\n"
     ]
    }
   ],
   "source": [
    "acc_RF= round(random_forest.score(x_train, y_train)*100,2)\n",
    "print(acc_RF)\n",
    "acc_MLR= round(reg.score(x_train, y_train)*100,2)\n",
    "print(acc_MLR)\n",
    "acc_knn= round(knn.score(x_train, y_train)*100,2)\n",
    "print(acc_knn)\n",
    "acc_NB= round(gaussian.score(x_train, y_train)*100,2)\n",
    "print(acc_NB)\n",
    "acc_linear_svc= round(linear_svc.score(x_train, y_train)*100,2)\n",
    "print(acc_linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testNames = test[\"name\"]\n",
    "#testIDs = test[\"Id\"]\n",
    "testExpected = []\n",
    "for i in range (0, len(test_ID)):\n",
    "    #name = testNames[i]\n",
    "    posC = 0\n",
    "    negC = 0\n",
    "    posOverall = 0\n",
    "    for word in positiveWords:\n",
    "        wordCount = test[word][i]\n",
    "        posC+=wordCount\n",
    "    for word in negativeWords:\n",
    "        wordCount = test[word][i]\n",
    "        negC+=wordCount \n",
    "    if posC > negC:\n",
    "        posOverall = 1\n",
    "    elif posC < negC:\n",
    "        posOverall = -1.5\n",
    "    else:\n",
    "        posOverall = 0\n",
    "    nword = np.array(test[\"nword\"])[i]\n",
    "    nchar = np.array(test[\"nchar\"])[i]\n",
    "    avgChar = nchar/nword\n",
    "    if negC>3:\n",
    "        negativep = -1\n",
    "    else:\n",
    "        negativep = 0\n",
    "    #numReviews = ratingCount[name]\n",
    "    standnchars = (nchar-599.985124)/(534.629585)\n",
    "    if nword<110:\n",
    "        pns = posC * 1.5\n",
    "        nnl = negC\n",
    "    else:\n",
    "        pns = posC\n",
    "        nnl = negC * 1.5\n",
    "    #posnegratio = ((posC)/(negC + 1))\n",
    "    #predictors = np.array([[posC, negC, rating]])\n",
    "    predictors = np.array([[posOverall, pns, nnl, standnchars, negativep]])\n",
    "    prediction = random_forest.predict(predictors)\n",
    "    #prediction = prediction+rating\n",
    "    testExpected.append(prediction[0])\n",
    "    #print(prediction)\n",
    "submitDF = pd.DataFrame({'Id':test_ID, 'Expected':testExpected})\n",
    "submitDF.to_csv(\"submission04.csv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
